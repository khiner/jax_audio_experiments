{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "* ~Try a built-in optimizer (like grad descent w/ momentum) instead of constant learning rate. See how convergence time changes~\n",
    "* ~Plot loss~\n",
    "* ~Refactor (processors are modules)~\n",
    "* ~Define `init_params` methods for each processor, initializing to params that have no effect on the signal (no-op  prior)~\n",
    "  - this is something to note in writeup. talk about small changes to params having big effect in processors with feedback. And how starting from no effect initially is good for live performance settings.\n",
    "* ~Add a simple clipping nonlinearity effect to see how `grad` does with that~\n",
    "* ~Refactoring~\n",
    "  - ~Use dicts for labeled params instead of n-d arrays (jax handles this)~\n",
    "  - ~Move parameter label creation into processor fns~\n",
    "* ~Estimate params for multiple serially-connected filters (create a general `serial_processors` processor)~\n",
    "* ~~Run on GPU & measure performance differences~~\n",
    "  - Performance is indeed much better on a GPU, despite the serial bottlneck of the IIR filters.\n",
    "  - E.g. for a length-5 IIR filter with an input sequence of length 300, on a GPU:\n",
    "    `CPU times: user 14.6 s, sys: 664 ms, total: 15.3 s, Wall time: 15.7 s`.\n",
    "    On the CPU, it wouldn't even finish for more than 5 minutes so I stopped it and dropped the input length to 100, and got these numbers; `CPU times: user 37.1 s, sys: 816 ms, total: 38 s, Wall time: 37.7 s`\n",
    "* Add `processArray` methods to all processors, which will allow for fast convolution FIR implementations\n",
    "* Add a `DelayLine` processor. This is fundamentally a FIR filter, with the important difference that it's only parameterized by a couple params (like delay length and dry/wet level), rather than one param for each coefficient. The single-sample `tick` method can show off the ability to implement in the more traditional read/write pointer style as well.\n",
    "* Add `AllpassFilter` and `CombFilter` processors\n",
    "* How to speed up IIR filters (like allpass filters)?\n",
    "  - What if we estimate parameters without running across the full input sample? Like just test against a very small input sample? E.g. a length-5 IIR filter shouldn't need to backprop against every sample of a 2-second clip. That's just super redundant, right? Its behavior should be fully determinable from an input sample of a length on the order of the coefficients I think. This could generalize to other processors as well. (Maybe something like a `testLength` for each processor.) Should be able to test this well by comparing loss as `testLength` drops.\n",
    "* Test on a realistic 4-second audio signal at 24kHz\n",
    "* Animate changes in output signal over time, compared with target\n",
    "* Try batches of short sample pairs (more than just single unit impulse signal) and see if it finds parameters closer to ground truth. Also, chart number of batches to some loss vs number of training pairs per batch.\n",
    "  - If multiple training pairs would help gradient descent for this problem, then we could do training batches in parallel. Iâ€™m not sure if this is necessary for the LTI case, since a single unit impulse input should fully determine the output behavior for arbitrary inputs. But maybe seeing more diverse pairs would help find better gradient estimates in general? At the very least, fewer total batches should be needed to achieve the same loss as batch size increases, so training should speed up if we can train multiple streams in parallel per-batch.\n",
    "* Use a perceptual loss function instead of mse (steal DDSP's multi-scale spectral loss fn)\n",
    "* Improve performance\n",
    "  - ~Speed things up with [JIT](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Using-jit-to-speed-up-functions)~\n",
    "* ~I don't think functions truly need to be pure. I tried passing in a plain np array and changing it in place and it seemed to work fine. Maybe we can use shared buffers to improve memory usage?~\n",
    "  - Answer - this is because you can create and use state _inside_ functions transformed by JAX. I found a decent middleground here that lets me use processor classes with internal state by instantiating them inside the transformed fn.\n",
    "* End-goal (ready for blog post): [Implement freeverb and perform dereverbing](https://trello.com/c/NSnb806w/2-goal-parameterize-freeverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from scipy import signal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "sys.path.append('./processors')\n",
    "from fir_filter import FirFilter\n",
    "from iir_filter import IirFilter\n",
    "from clip import Clip\n",
    "from plotters import plot_filter, plot_loss, plot_params\n",
    "from train import train, train_serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = jnp.concatenate([jnp.array([1.0]), jnp.zeros(160)])\n",
    "params_estimated, params_target, Y_estimated, Y_target, params_history, loss_history = train(FirFilter, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params_estimated, params_target, Y_estimated, Y_target, params_history, loss_history = train(FirFilter, X, buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(loss_history)\n",
    "plot_params(params_target, params_history)\n",
    "Y_reference = signal.lfilter(params_target['B'], [1.0], X)\n",
    "plot_filter(X, Y_target, Y_reference, Y_estimated, 'FIR Filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params_estimated, params_target, Y_estimated, Y_target, params_history, loss_history = train(IirFilter, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params_estimated, params_target, Y_estimated, Y_target, params_history, loss_history = train(IirFilter, X, buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(loss_history)\n",
    "plot_params(params_target, params_history)\n",
    "Y_reference = signal.lfilter(params_target['B'], params_target['A'], X)\n",
    "plot_filter(X, Y_target, Y_reference, Y_estimated, 'IIR Filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = np.random.uniform(-2, 2, X.size)\n",
    "params_estimated, params_target, Y_estimated, Y_target, params_history, loss_history = train(Clip, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(loss_history)\n",
    "plot_params(params_target, params_history)\n",
    "Y_reference = np.clip(X, params_target['min'], params_target['max'])\n",
    "plot_filter(X, Y_target, Y_reference, Y_estimated, 'Clipping nonlinearity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = np.random.uniform(-2, 2, X.size)\n",
    "params_estimated, params_target, Y_estimated, Y_target, params_history, loss_history = train_serial([IirFilter, Clip], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(loss_history)\n",
    "plot_params(params_target['iir_filter'], params_history['iir_filter'])\n",
    "plot_params(params_target['clip'], params_history['clip'])\n",
    "\n",
    "plot_filter(X, Y_target, None, Y_estimated, 'IIR Filter + Clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython\n",
    "# from scipy.io.wavfile import read as wavread\n",
    "\n",
    "# wav_fs, audio = wavread('speech-male.wav')\n",
    "# audio = audio.astype(float) / audio.max()\n",
    "# print('Original audio:')\n",
    "# IPython.display.Audio(audio, rate=wav_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1_000_000 / 44_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
