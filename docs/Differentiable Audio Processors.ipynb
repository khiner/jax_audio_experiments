{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "* ~Try a built-in optimizer (like grad descent w/ momentum) instead of constant learning rate. See how convergence time changes~\n",
    "* ~Plot loss~\n",
    "* ~Refactor (processors are modules)~\n",
    "* ~Define `init_params` methods for each processor, initializing to params that have no effect on the signal (no-op  prior)~\n",
    "  - this is something to note in writeup. talk about small changes to params having big effect in processors with feedback. And how starting from no effect initially is good for live performance settings.\n",
    "* ~Add a simple clipping nonlinearity effect to see how `grad` does with that~\n",
    "* ~Refactoring~\n",
    "  - ~Use dicts for labeled params instead of n-d arrays (jax handles this)~\n",
    "  - ~Move parameter label creation into processor fns~\n",
    "* ~Estimate params for multiple serially-connected filters (create a general `serial_processors` processor)~\n",
    "* ~~Run on GPU & measure performance differences~~\n",
    "  - ~~Performance is indeed much better on a GPU, despite the serial bottlneck of the IIR filters.~~\n",
    "  - ~~E.g. for a length-5 IIR filter with an input sequence of length 300, on a GPU:\n",
    "    `CPU times: user 14.6 s, sys: 664 ms, total: 15.3 s, Wall time: 15.7 s`.\n",
    "    On the CPU, it wouldn't even finish for more than 5 minutes so I stopped it and dropped the input length to 100, and got these numbers; `CPU times: user 37.1 s, sys: 816 ms, total: 38 s, Wall time: 37.7 s`~~\n",
    "* ~~Add `tick_buffer` methods to all processors, which will allow for fast convolution FIR implementations and use of `lax.scan`~~\n",
    "* ~~How to speed up IIR filters (like allpass filters)?~~ This is basically completely resolved with the current `lax.scan`-based implementation!\n",
    "* ~~Use minibatches instead of just a single unit impulse signal. See if it finds parameters closer to ground truth.~~\n",
    "  - Done - averaging gradients over minibatches doesn't seem to have a big effect on accuracy. But it's good to have this in place and using `vmap` to vectorize across multiple training pairs provides some speedup\n",
    "* ~~Try different optimizers, learning rates, gradient clipping, and any other techniques to guide to better parameter spaces for IIR filters (always wants to over-compensate with a large a[0] parameter to scale the full output)~~\n",
    "  - Eh, I tried a few optimizers, learning rates, tried weight norm clipping. I ultimately just stopped optimizing the output gain param in the IIR filter (`a[0]`) since it's not commonly used anyway.\n",
    "* Add a `DelayLine` processor. This is fundamentally a FIR filter, with the important difference that it's only parameterized by a couple params (like delay length and dry/wet level), rather than one param for each coefficient. The single-sample `tick` method can show off the ability to implement in the more traditional read/write pointer style as well.\n",
    "  - Having a lot of trouble finding a way to find a gradient on a parameter that controls delay length, since the gradient \"gets lost\". Lots more details in the \"Differentiable array indexing\" notebook.\n",
    "  - ~~Investigate [variable_length_delay DDSP effect](https://github.com/magenta/ddsp/blob/master/ddsp/core.py#L1009-L1037) & usage. They take a different approach - might find some inspiration.~~\n",
    "    * Welp, they only implement a _feed-forward_ delay. My goal here is a feedback delay. Still, I'm having the same issue with my FF delay, so there might be something about their parameterization or technique that I can learn from.\n",
    "  - ~~Plot optimization for different starting guesses, to help get a sense of why the gradient is blocked outside the +/- 1 range from initial delay-length param to target.~~\n",
    "* Add `AllpassFilter` and `CombFilter` processors\n",
    "* Test on a realistic 4-second audio signal at 24kHz\n",
    "* Animate changes in output signal over time, compared with target\n",
    "* Use a perceptual loss function instead of mse (steal DDSP's multi-scale spectral loss fn)\n",
    "* Improve performance\n",
    "  - ~Speed things up with [JIT](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Using-jit-to-speed-up-functions)~\n",
    "  - What if we estimate parameters without running across the full input sample? Like just test against a very small input sample? E.g. a length-5 IIR filter shouldn't need to backprop against every sample of a 2-second clip. That's just super redundant, right? Its behavior should be fully determinable from an input sample of a length on the order of the coefficients I think. This could generalize to other processors as well. (Maybe something like a `testLength` for each processor.) Should be able to test this well by comparing loss as `testLength` drops.\n",
    "* ~I don't think functions truly need to be pure. I tried passing in a plain np array and changing it in place and it seemed to work fine. Maybe we can use shared buffers to improve memory usage?~\n",
    "  - Answer - this is because you can create and use state _inside_ functions transformed by JAX. I found a decent middleground here that lets me use processor classes with internal state by instantiating them inside the transformed fn.\n",
    "* End-goal (ready for blog post): [Implement freeverb and perform dereverbing](https://trello.com/c/NSnb806w/2-goal-parameterize-freeverb)\n",
    "  - Implement [Lowpass Feedback Comb Filter](https://ccrma.stanford.edu/~jos/pasp/Lowpass_Feedback_Comb_Filter.html) as pure IIR filter(s)\n",
    "* Most similar paper: [Differentiable IIR Filters for Machine Learning Applications (2020)](https://www.dafx.de/paper-archive/details.php?id=rA_6fTdLky8YDvH03jdufw)\n",
    "  - Replicate their Boss DS-1 pedal experiment and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../jax_audio_processors')\n",
    "sys.path.append('../jax_audio_processors/processors')\n",
    "import fir_filter, iir_filter, clip, delay_line, lowpass_feedback_comb_filter as lbcf, allpass_filter, freeverb, serial_processors\n",
    "from plotting import plot_filter, plot_loss, plot_params, plot_optimization\n",
    "from train import train, evaluate, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_with_one_at(i, size):\n",
    "    ar = np.zeros(size)\n",
    "    ar[i] = 1.0\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.3\n",
    "n_batches = 1_000\n",
    "batch_size = 2\n",
    "n_train = 100\n",
    "samples_per_second = 44_100\n",
    "n_samples = 200 # 4 * samples_per_second\n",
    "Xs_random = np.random.randn(n_train, n_samples)\n",
    "Xs_unit = np.array([array_with_one_at(i, n_samples) for i in range(n_train)])\n",
    "Xs_chirp = np.array(np.split(signal.chirp(np.linspace(0, 10, n_train * n_samples), f0=300, f1=1, t1=10), n_train))\n",
    "#Xs_chirp = np.ones((n_train,1)) * signal.chirp(np.linspace(0, 10, n_samples), f0=10, f1=1, t1=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_processors(processors, Xs=Xs_chirp, reference_fn=None,\n",
    "                        plot_loss_history=True, plot_params_history=True):\n",
    "    start = time.time()\n",
    "    params_estimated, params_target, params_history, loss_history = train(processors, Xs, step_size=step_size, num_batches=n_batches, batch_size=batch_size)\n",
    "    print('Train time: {:.3E} s'.format(time.time() - start))\n",
    "    print('Loss: {:.3E}'.format(loss_history[-1]))\n",
    "    X_eval = Xs[0]\n",
    "    Y_estimated, Y_target = evaluate(params_estimated, params_target, serial_processors, X_eval, processors)\n",
    "    Y_reference = reference_fn(X_eval, params_target) if reference_fn is not None else None\n",
    "\n",
    "    print(params_estimated)\n",
    "    if plot_loss_history:\n",
    "        plot_loss(loss_history)\n",
    "    if plot_params_history:\n",
    "        plot_params(params_target, params_history)\n",
    "    title = ' + '.join(processor.NAME for processor in processors)\n",
    "    plot_filter(X_eval, Y_target, Y_reference, Y_estimated, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([freeverb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size timing notes:\n",
    "\n",
    "    Batch size: 1, step size: 0.3\n",
    "    Train time: 3.078E+01 s\n",
    "    Loss: 9.079E-16\n",
    "    \n",
    "    Batch size: 2, step size: 0.3\n",
    "    Train time: 3.591E+01 s\n",
    "    Loss: 4.967E-14\n",
    "    \n",
    "    Batch size: 4, step size: 0.3\n",
    "    Train time: 3.829E+01 s\n",
    "    Loss: 3.683E-14\n",
    "\n",
    "    Batch size: 4, step size: 0.4\n",
    "    Train time: 3.989E+01 s\n",
    "    Loss: 1.124E-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_processors([lbcf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([allpass_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([delay_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([fir_filter], reference_fn=lambda X, params: signal.lfilter(params[fir_filter.NAME]['B'], [1.0], X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([iir_filter], reference_fn=lambda X, params: signal.lfilter(params[iir_filter.NAME]['B'], params[iir_filter.NAME]['A'], X), plot_params_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([clip], reference_fn=lambda X, params: np.clip(X, params[clip.NAME]['min'], params[clip.NAME]['max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([iir_filter, clip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_inits = [{'delay_samples': delay_samples, 'wet_amount': 1.0} for delay_samples in np.linspace(3, 10, 50)]\n",
    "params_target = {'wet_amount': 1.0, 'delay_samples': 7.0}\n",
    "# plot_optimization(delay_line, Xs_chirp, param_inits, params_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: verify Lagrange interpolation converges over a 4-sample range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Freeverb\n",
    "\n",
    "From [Physical Audio Signal Processing](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html):\n",
    "\n",
    "![](https://ccrma.stanford.edu/~jos/pasp/img728_2x.png)\n",
    "\n",
    "It is composed of [lowpass feedback comb filters](https://ccrma.stanford.edu/~jos/pasp/Lowpass_Feedback_Comb_Filter.html) and [Schroeder allpass sections](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Allpass_Sections.html).\n",
    "\n",
    "In order to implement Freeverb in a differentiable way, I will use plain IIR filters for each component. (Note that this is extremely inefficient compared with the direct implementation of the difference equation.) (See issues in differentiable parameterizing of delay line length above.)\n",
    "\n",
    "\n",
    "$H_{AP}(z)= \\dfrac{X(z)}{Y(z)} =\\dfrac{g^∗+z^{−m}}{1+gz^{−m}}$\n",
    "\n",
    "$\\begin{align}\n",
    "H_{LBCF}(z) &= \\dfrac{z^{-N}}{1-f\\frac{1-d}{1-dz^{-1}}z^{-N}}\\\\\n",
    "&= \\dfrac{z^{-N}}{\\frac{1-dz^{-1}-f(1-d)z^{-N}}{1-dz^{-1}}}\\\\\n",
    "&= \\dfrac{z^{-N}(1-dz^{-1})}{1-dz^{-1}-f(1-d)z^{-N}}\\\\\n",
    "&= \\dfrac{-dz^{-N-1}+z^{-N}}{1-dz^{-1}-f(1-d)z^{-N}}\\\\\n",
    "\\end{align}$\n",
    "\n",
    "TODO: verify the behavior is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
