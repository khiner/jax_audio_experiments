{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "%pip install jax jaxlib --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from jaxdsp import training\n",
    "from jaxdsp.processors import fir_filter, iir_filter, clip, delay_line, lowpass_feedback_comb_filter as lbcf, allpass_filter, freeverb, sine_wave, serial_processors\n",
    "from jaxdsp.plotting import plot_filter, plot_loss, plot_params, plot_optimization\n",
    "from jaxdsp.loss import create_loss_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.1\n",
    "num_train = 100\n",
    "\n",
    "buffer_size = 44100\n",
    "Xs_random = np.random.randn(num_train, buffer_size)\n",
    "Xs_chirp = np.array(np.split(signal.chirp(np.linspace(0.0, num_train, num_train * buffer_size), f0=10, f1=1000, t1=num_train), num_train))\n",
    "\n",
    "default_loss_opts = create_loss_opts(\n",
    "    weights={\n",
    "        \"sample\": 1.0,\n",
    "    },\n",
    "    sample_distance_type=\"L2\",\n",
    ")\n",
    "spectral_loss_opts = create_loss_opts(\n",
    "    weights={\n",
    "        \"cumsum_freq\": 1.0,\n",
    "    },\n",
    "    sample_distance_type=\"L2\",\n",
    "    freq_distance_type=\"L2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_processors(processors, loss_opts=default_loss_opts, Xs=Xs_chirp, num_batches=100, reference_fn=None,\n",
    "                        plot_loss_history=True, plot_params_history=True, title=None):\n",
    "    processor = serial_processors\n",
    "    processor_config = serial_processors.config(processors)\n",
    "    trainer = training.IterativeTrainer(processor, training.Config(loss_opts, step_size=step_size),\n",
    "                                        processor_config, track_history=True)\n",
    "\n",
    "    carry_target = {'params': processor_config.params_target, 'state': processor_config.state_init}\n",
    "    start = time.time()\n",
    "    for i in range(num_batches):\n",
    "        # X = Xs[i % Xs.shape[0]]\n",
    "        X = Xs[np.random.choice(Xs.shape[0])]\n",
    "        carry_target, Y_target = processor.tick_buffer(carry_target, X)\n",
    "        trainer.step(X, Y_target)\n",
    "\n",
    "    params_estimated = trainer.params()\n",
    "    carry_estimated = {'params': params_estimated, 'state': trainer.processor_state}\n",
    "    print('Train time: {:.3E} s'.format(time.time() - start))\n",
    "    print('Loss: {:.3E}'.format(trainer.loss))\n",
    "    print('Estimated params: ', params_estimated)\n",
    "\n",
    "    X_eval = Xs[0]\n",
    "    Y_estimated, Y_target = training.evaluate(carry_estimated, carry_target, processor, X_eval)\n",
    "    Y_reference = reference_fn(X_eval, carry_target['params']) if reference_fn is not None else None\n",
    "\n",
    "    if plot_loss_history:\n",
    "        plot_loss(trainer.step_evaluator.loss_history)\n",
    "    if plot_params_history:\n",
    "        plot_params(training.float_params(carry_target['params']), trainer.step_evaluator.params_history)\n",
    "    plot_filter(X_eval, Y_target, Y_reference, Y_estimated, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_processors([lbcf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([sine_wave], loss_opts=spectral_loss_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([freeverb], num_batches=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([allpass_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([delay_line], loss_opts=spectral_loss_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([fir_filter], Xs=Xs_random, reference_fn=lambda X, params: signal.lfilter(params[fir_filter.NAME]['B'], [1.0], X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([iir_filter], Xs=Xs_random, reference_fn=lambda X, params: signal.lfilter(params[iir_filter.NAME]['B'], params[iir_filter.NAME]['A'], X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([clip], reference_fn=lambda X, params: np.clip(X, params[clip.NAME]['min'], params[clip.NAME]['max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_processors([iir_filter, clip], num_batches=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Freeverb\n",
    "\n",
    "From [Physical Audio Signal Processing](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html):\n",
    "\n",
    "![](https://ccrma.stanford.edu/~jos/pasp/img728_2x.png)\n",
    "\n",
    "It is composed of [lowpass feedback comb filters](https://ccrma.stanford.edu/~jos/pasp/Lowpass_Feedback_Comb_Filter.html) and [Schroeder allpass sections](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Allpass_Sections.html).\n",
    "\n",
    "In order to implement Freeverb in a differentiable way, I will use plain IIR filters for each component. (Note that this is extremely inefficient compared with the direct implementation of the difference equation.) (See issues in differentiable parameterizing of delay line length above.)\n",
    "\n",
    "\n",
    "$H_{AP}(z)= \\dfrac{X(z)}{Y(z)} =\\dfrac{g^∗+z^{−m}}{1+gz^{−m}}$\n",
    "\n",
    "$\\begin{align}\n",
    "H_{LBCF}(z) &= \\dfrac{z^{-N}}{1-f\\frac{1-d}{1-dz^{-1}}z^{-N}}\\\\\n",
    "&= \\dfrac{z^{-N}}{\\frac{1-dz^{-1}-f(1-d)z^{-N}}{1-dz^{-1}}}\\\\\n",
    "&= \\dfrac{z^{-N}(1-dz^{-1})}{1-dz^{-1}-f(1-d)z^{-N}}\\\\\n",
    "&= \\dfrac{-dz^{-N-1}+z^{-N}}{1-dz^{-1}-f(1-d)z^{-N}}\\\\\n",
    "\\end{align}$\n",
    "\n",
    "TODO: verify the behavior is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
